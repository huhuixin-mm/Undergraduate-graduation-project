## 1、7B以内具有thinking能力的大模型



| 模型名称 | 参数量 | 开发团队 | 简介 | 链接 |
|:-:|:--:|:-:|:-:|:-:|
| **Mistral-7B** | ~7B | Mistral AI | Mistral 发布的高性能 7B 解码器模型，指令跟从与推理能力强，适合本地部署与微调，基线性能优于许多更大尺寸模型。 | Hugging Face: https://huggingface.co/mistralai/Mistral-7B-v0.1 |
| **Mixtral-8x7B (稀疏 MoE)** | 8×7B（稀疏 MoE 架构） | Mistral AI | Mixtral-8x7B 为稀疏 Mixture-of-Experts 设计（8 个 7B 专家），在多项 benchmark 上表现突出，适合算力-性能折中场景。 | Hugging Face: https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1 |
| **LLaMA-2 (7B)** | 7B | Meta | Meta 的 LLaMA-2 系列中的 7B 基线模型，广泛被社区用于微调、指令调优与聊天系统（LLaMA-2-Chat），许可面向研究/产品使用。 | Hugging Face: https://huggingface.co/meta-llama/Llama-2-7b |
| **Gemma-7B** | 7B | Google / DeepMind (Gemma 系列) | Google 推出的 Gemma 轻量系列包含 7B 大小（预训练与 instruction-tuned），官方提供多框架的训练/推理工具与安全指南。 | 官方公告: https://blog.google/technology/developers/gemma-open-models/ |
| **Qwen-7B (通义)** | 7B | Alibaba / Qwen 团队 | 阿里云的 Qwen 系列包含 7B（含基础与 chat/instruct），在中文与代码场景上表现优异，并在 Hugging Face / GitHub 上有开源资源。 | Hugging Face / Repo: https://huggingface.co/Qwen/Qwen-7B |
| **DeepSeek-LLM 7B Base** | 7B | DeepSeek-AI | 基于 pre-norm 解码器架构（RoPE、GQA、SwiGLU），使用中英双语 2T tokens 预训练。性能优于同时期开源模型，适合研究推理与语言生成任务。 | Hugging Face: https://huggingface.co/deepseek-ai/deepseek-llm-7b-base |
| **DeepSeek-LLM 7B Chat** | 7B | DeepSeek-AI | 在 Base 基础上进行监督微调（SFT）以实现指令跟从，对话能力增强，适合聊天与交互场景。 | Hugging Face: https://huggingface.co/deepseek-ai/deepseek-llm-7b-chat |
| **Yi-6B** | 6B（接近 7B） | 01.AI | 国产大模型代表之一，中文能力强，开放 base/chat 两种版本，表现力接近 7B 水平，经常被和 7B 模型一起比较。 | Hugging Face: https://huggingface.co/01-ai/Yi-6B |
| **Xwin-LM-7B** | 7B | 社区（基于 LLaMA 微调） | 针对对话与推理优化的 LLaMA-2-7B 微调版本，在 AlpacaEval、MT-Bench 等榜单上常见。 | Hugging Face: https://huggingface.co/Xwin-LM/Xwin-LM-7B-V0.1 |
| **Vicuna-7B** | 7B | LMSYS | 最早的高质量开源聊天微调模型之一，基于 LLaMA-7B 微调，MT-Bench 表现优异，推动了开源社区的对话模型潮流。 | Hugging Face: https://huggingface.co/lmsys/vicuna-7b-v1.5 |
| **OpenLLaMA-7B** | 7B | Together Computer | 使用开源数据重训的 LLaMA 替代版本，完全开放权重，社区常用于复现和研究。 | Hugging Face: https://huggingface.co/openlm-research/open_llama_7b |
| **H2O-Danube-7B** | 7B | H2O.ai | 基于 LLaMA2-7B 指令微调的模型，Apache-2.0 许可，常用于企业与研究部署。 | Hugging Face: https://huggingface.co/h2oai/h2o-danube-7b-chat |



## 2、如何基于知识图谱增强大模型的思维能力





用KG可以增强LLM的**可解释性**

预训练阶段：比较典型的方法又分为三种：将知识图谱整合进训练目标、将知识图谱整合进大模型的输入、将知识图谱整合进附加的融合模块

推理阶段：第一种是将LLM和知识图谱进行动态融合，第二种则是比较常见的通过检索外部知识来增强LLM

### (1) RAG (retrieval-augmented generation)

含义：从外部知识库检索相关信息作为上下文一同提供给大模型。

优点：

- 能减小模型的“幻觉”  
- 无需重新训练模型，只需更新知识图谱，即可让模型获取最新知识  
- 生成的答案有据可查，增强了透明度和可解释性  

### (2) Reasoning & Planning

含义：让大模型利用知识图谱的图结构，进行多步、复杂的逻辑推理。模型需要理解问题并将其分解，然后在图谱上进行“多跳查询”，最后综合得出答案。

优点：

- 解决复杂问题：增强了模型进行深层次、多步骤逻辑推理（如因果、时序推理）的能力。

- 实现知识关联：不再是孤立地看待事实，而是能够发现和利用实体之间隐藏的、间接的关联，进行更深度的知识探索。

### (3) Synergy & Feedback

含义：不仅用知识图谱来增强大模型，同时也利用大模型强大的自然语言处理能力来构建、扩展和优化知识图谱本身。

优点：

- 自动化知识库构建：极大地降低了构建和维护知识图谱的人工成本，实现了知识库的自动化和规模化扩展。

- 知识校验与纠错：利用大模型的广泛知识，可以发现并修正知识图谱中可能存在的错误或矛盾，提升知识库的质量。





